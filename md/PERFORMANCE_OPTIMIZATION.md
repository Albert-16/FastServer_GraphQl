# Optimizaci√≥n de Rendimiento para Producci√≥n

## üö® Problemas Cr√≠ticos Detectados

### Problema 1: GetAllAsync carga TODOS los registros en memoria
**Ubicaci√≥n:** `LogServicesHeaderService.GetAllAsync` (l√≠neas 95-99)

```csharp
// ‚ùå PROBLEMA: Carga TODOS los registros antes de paginar
var totalCount = await uow.LogServicesHeaders.CountAsync(cancellationToken);
var entities = await uow.LogServicesHeaders.GetAllAsync(cancellationToken);  // ‚Üê Trae TODOS los registros

var pagedEntities = entities
    .Skip(pagination.Skip)   // ‚Üê Paginaci√≥n en memoria (LENTO)
    .Take(pagination.PageSize)
    .ToList();
```

**Impacto:**
- Con 10,000 registros: ~2-3 segundos
- Con 100,000 registros: ~10-20 segundos
- Con 1,000,000 registros: Out of Memory Exception

**Soluci√≥n requerida:**
```csharp
// ‚úÖ SOLUCI√ìN: Paginar en la base de datos
var entities = await uow.LogServicesHeaders
    .Query()
    .OrderByDescending(x => x.LogDateIn)
    .Skip(pagination.Skip)
    .Take(pagination.PageSize)
    .ToListAsync(cancellationToken);

var totalCount = await uow.LogServicesHeaders.CountAsync(cancellationToken);
```

### Problema 2: Falta de √≠ndices en base de datos
**Consultas sin √≠ndices = escaneo completo de tabla**

#### √çndices para PostgreSQL (Base de datos actual/principal):
```sql
-- Para ordenamiento y paginaci√≥n
CREATE INDEX ix_logservices_logdatein ON "FastServer_LogServices_Header"(fastserver_log_date_in DESC);

-- Para filtros comunes
CREATE INDEX ix_logservices_state ON "FastServer_LogServices_Header"(fastserver_log_state);
CREATE INDEX ix_logservices_microservice ON "FastServer_LogServices_Header"(fastserver_microservice_name);
CREATE INDEX ix_logservices_userid ON "FastServer_LogServices_Header"(fastserver_user_id);

-- √çndice compuesto para consultas complejas
CREATE INDEX ix_logservices_datestate ON "FastServer_LogServices_Header"(fastserver_log_date_in DESC, fastserver_log_state);

-- Optimizaci√≥n espec√≠fica PostgreSQL: √≠ndice parcial para logs activos
CREATE INDEX ix_logservices_active_logs ON "FastServer_LogServices_Header"(fastserver_log_date_in DESC)
WHERE fastserver_log_state = 2; -- Solo logs completados
```

#### √çndices para SQL Server (Base de datos secundaria):
```sql
-- Para ordenamiento y paginaci√≥n
CREATE INDEX IX_LogServices_LogDateIn ON FastServer_LogServices_Header(fastserver_log_date_in DESC);

-- Para filtros comunes
CREATE INDEX IX_LogServices_State ON FastServer_LogServices_Header(fastserver_log_state);
CREATE INDEX IX_LogServices_Microservice ON FastServer_LogServices_Header(fastserver_microservice_name);
CREATE INDEX IX_LogServices_UserId ON FastServer_LogServices_Header(fastserver_user_id);

-- √çndice compuesto para consultas complejas
CREATE INDEX IX_LogServices_DateState ON FastServer_LogServices_Header(fastserver_log_date_in DESC, fastserver_log_state)
INCLUDE (fastserver_microservice_name, fastserver_user_id); -- Covering index
```

### Problema 3: No hay cach√© implementado
**Cada query va a la base de datos**, incluso para datos que cambian poco.

## üìä Respuesta a tus Preguntas

### ¬øCumple con el prop√≥sito de respuestas r√°pidas?

**Estado actual: NO ‚ùå**
- Query simple: 2.8 segundos (INACEPTABLE para producci√≥n)
- Meta para producci√≥n: < 200ms para queries simples

**Despu√©s de optimizaciones: S√ç ‚úÖ**
- Con √≠ndices + paginaci√≥n correcta: < 100ms
- Con cach√©: < 10ms para datos frecuentes

### ¬øEl cambio de origen de datos est√° automatizado?

**S√ç ‚úÖ - Perfectamente dise√±ado**

```json
// Cambio de PostgreSQL a SQL Server (o viceversa)
// Solo cambiar UNA l√≠nea en appsettings.json:
{
  "DefaultDataSource": "SqlServer"  // ‚Üê Cambiar aqu√≠
}
```

**Ventajas de la arquitectura actual:**
1. ‚úÖ Cero cambios de c√≥digo
2. ‚úÖ Solo reiniciar la aplicaci√≥n
3. ‚úÖ Funciona con una o ambas bases de datos
4. ‚úÖ Queries espec√≠ficas pueden usar origen diferente al predeterminado

**Si el d√≠a de ma√±ana unifican en un solo origen:**
1. Eliminar cadena de conexi√≥n no usada de appsettings.json
2. Cambiar `DefaultDataSource` al √∫nico origen
3. Listo - cero cambios de c√≥digo

## üöÄ Plan de Optimizaci√≥n Recomendado

### Fase 1: Correcciones Cr√≠ticas (Urgente)

#### 1.1 Arreglar paginaci√≥n en GetAllAsync
```csharp
public async Task<PaginatedResultDto<LogServicesHeaderDto>> GetAllAsync(
    PaginationParamsDto pagination,
    DataSourceType? dataSource = null,
    CancellationToken cancellationToken = default)
{
    using var uow = _dataSourceFactory.CreateUnitOfWork(dataSource ?? _defaultDataSource);

    // Ejecutar en paralelo: query paginada + count total
    var queryTask = uow.LogServicesHeaders
        .Query()
        .OrderByDescending(x => x.LogDateIn)
        .Skip(pagination.Skip)
        .Take(pagination.PageSize)
        .ToListAsync(cancellationToken);

    var countTask = uow.LogServicesHeaders.CountAsync(cancellationToken);

    await Task.WhenAll(queryTask, countTask);

    return new PaginatedResultDto<LogServicesHeaderDto>
    {
        Items = _mapper.Map<IEnumerable<LogServicesHeaderDto>>(queryTask.Result),
        TotalCount = countTask.Result,
        PageNumber = pagination.PageNumber,
        PageSize = pagination.PageSize
    };
}
```

#### 1.2 Agregar √≠ndices a la base de datos
Ver scripts SQL arriba.

**Impacto esperado:** 2.8s ‚Üí 100-200ms (mejora de 10-20x)

### Fase 2: Cach√© (Importante)

#### 2.1 Implementar cach√© distribuido
```bash
dotnet add package Microsoft.Extensions.Caching.StackExchangeRedis
```

```csharp
// En Program.cs
builder.Services.AddStackExchangeRedisCache(options =>
{
    options.Configuration = builder.Configuration.GetConnectionString("Redis");
    options.InstanceName = "FastServer_";
});
```

#### 2.2 Agregar cach√© a servicios
```csharp
public class LogServicesHeaderService
{
    private readonly IDistributedCache _cache;

    public async Task<LogServicesHeaderDto?> GetByIdAsync(long id, ...)
    {
        // Intentar obtener del cach√©
        var cacheKey = $"log:{id}:{dataSource}";
        var cached = await _cache.GetStringAsync(cacheKey, cancellationToken);

        if (cached != null)
            return JsonSerializer.Deserialize<LogServicesHeaderDto>(cached);

        // Si no est√° en cach√©, consultar BD
        using var uow = _dataSourceFactory.CreateUnitOfWork(dataSource ?? _defaultDataSource);
        var entity = await uow.LogServicesHeaders.GetByIdAsync(id, cancellationToken);

        if (entity != null)
        {
            var dto = _mapper.Map<LogServicesHeaderDto>(entity);

            // Guardar en cach√© (5 minutos)
            await _cache.SetStringAsync(
                cacheKey,
                JsonSerializer.Serialize(dto),
                new DistributedCacheEntryOptions { AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5) },
                cancellationToken);

            return dto;
        }

        return null;
    }
}
```

**Impacto esperado:** Queries repetidas: 100ms ‚Üí 5-10ms

### Fase 3: Proyecciones y Select Espec√≠ficos

En lugar de cargar entidades completas, seleccionar solo campos necesarios:

```csharp
// ‚ùå Carga todos los campos
var entities = await uow.LogServicesHeaders.GetAllAsync();

// ‚úÖ Solo carga campos necesarios
var entities = await uow.LogServicesHeaders
    .Query()
    .Select(x => new LogServicesHeaderDto
    {
        LogId = x.LogId,
        LogDateIn = x.LogDateIn,
        MicroserviceName = x.MicroserviceName,
        // Solo campos necesarios
    })
    .ToListAsync();
```

**Impacto:** Reduce transferencia de red y uso de memoria en 50-70%

### Fase 4: Connection Pooling y Configuraci√≥n EF

#### Optimizaciones para PostgreSQL (Base de datos actual):
```csharp
// En DependencyInjection.cs
services.AddDbContext<PostgreSqlDbContext>(options =>
    options.UseNpgsql(postgresConnection, npgsqlOptions =>
    {
        npgsqlOptions.EnableRetryOnFailure(3);
        npgsqlOptions.CommandTimeout(30);

        // NUEVAS OPTIMIZACIONES POSTGRESQL:
        npgsqlOptions.MaxBatchSize(100);              // Batching para inserts/updates
        npgsqlOptions.UseQuerySplittingBehavior(     // Split queries complejas
            QuerySplittingBehavior.SplitQuery);
    })
    .EnableSensitiveDataLogging(false)           // Deshabilitar en producci√≥n
    .EnableDetailedErrors(false)                  // Deshabilitar en producci√≥n
    .UseQueryTrackingBehavior(                    // No tracking para queries read-only
        QueryTrackingBehavior.NoTracking));
```

**Optimizaciones adicionales PostgreSQL en appsettings.json:**
```json
{
  "ConnectionStrings": {
    "PostgreSQL": "Host=localhost;Port=5432;Database=FastServerLogs;Username=postgres;Password=***;Pooling=true;Minimum Pool Size=10;Maximum Pool Size=100;Connection Idle Lifetime=300;Connection Pruning Interval=10"
  }
}
```

**Beneficios del connection pooling en PostgreSQL:**
- `Pooling=true` - Habilita reutilizaci√≥n de conexiones
- `Minimum Pool Size=10` - Mantiene 10 conexiones calientes
- `Maximum Pool Size=100` - M√°ximo 100 conexiones simult√°neas
- `Connection Idle Lifetime=300` - Cierra conexiones inactivas despu√©s de 5 minutos
- `Connection Pruning Interval=10` - Limpia conexiones cada 10 segundos

#### Optimizaciones para SQL Server (Base de datos secundaria):
```csharp
services.AddDbContext<SqlServerDbContext>(options =>
    options.UseSqlServer(sqlServerConnection, sqlOptions =>
    {
        sqlOptions.EnableRetryOnFailure(3);
        sqlOptions.CommandTimeout(30);

        // NUEVAS OPTIMIZACIONES SQL SERVER:
        sqlOptions.MaxBatchSize(100);              // Batching para inserts/updates
        sqlOptions.UseQuerySplittingBehavior(     // Split queries complejas
            QuerySplittingBehavior.SplitQuery);
    })
    .EnableSensitiveDataLogging(false)           // Deshabilitar en producci√≥n
    .EnableDetailedErrors(false)                  // Deshabilitar en producci√≥n
    .UseQueryTrackingBehavior(                    // No tracking para queries read-only
        QueryTrackingBehavior.NoTracking));
```

### Fase 5: Compresi√≥n de Respuestas

```csharp
// En Program.cs
builder.Services.AddResponseCompression(options =>
{
    options.EnableForHttps = true;
    options.Providers.Add<GzipCompressionProvider>();
});

builder.Services.Configure<GzipCompressionProviderOptions>(options =>
{
    options.Level = System.IO.Compression.CompressionLevel.Fastest;
});

// En pipeline
app.UseResponseCompression();
```

**Impacto:** Reduce tama√±o de respuesta en 60-80%

## üìà M√©tricas de Rendimiento Esperadas

| Escenario | Sin Optimizaci√≥n | Con Optimizaci√≥n |
|-----------|------------------|------------------|
| Query simple por ID | 50-100ms | 5-10ms (con cach√©) |
| Lista paginada (10 items) | 2,800ms | 80-150ms |
| Lista paginada (con cach√©) | 2,800ms | 10-20ms |
| Query compleja con filtros | 5,000ms+ | 200-400ms |
| Throughput (req/seg) | ~10 | ~500-1000 |

## üîß Implementaci√≥n por Prioridad

### Alta Prioridad (Implementar YA)
1. ‚úÖ Arreglar paginaci√≥n en GetAllAsync
2. ‚úÖ Agregar √≠ndices en base de datos
3. ‚úÖ Configurar QueryTrackingBehavior.NoTracking

### Media Prioridad (Pr√≥ximas 2 semanas)
4. ‚ö†Ô∏è Implementar cach√© distribuido (Redis)
5. ‚ö†Ô∏è Proyecciones espec√≠ficas en queries
6. ‚ö†Ô∏è Compresi√≥n de respuestas

### Baja Prioridad (Mejora continua)
7. üìä Monitoreo y m√©tricas (Application Insights)
8. üìä Query optimization con EF Core logging
9. üìä Load testing con k6 o JMeter

## ‚úÖ Ventajas de la Arquitectura Actual

**Tu dise√±o multi-origen ya est√° perfectamente preparado para:**

1. **Migraci√≥n sin downtime:**
   ```
   PostgreSQL (origen actual)
   ‚Üì
   Ambos en paralelo (migraci√≥n gradual)
   ‚Üì
   SQL Server (origen nuevo)
   ```

2. **Replicaci√≥n Read/Write:**
   - Writes ‚Üí SQL Server
   - Reads ‚Üí PostgreSQL replica
   - Configurar por query con par√°metro `dataSource`

3. **Sharding geogr√°fico:**
   - US ‚Üí SQL Server
   - EU ‚Üí PostgreSQL
   - GraphQL decide din√°micamente

4. **Disaster Recovery:**
   - Si PostgreSQL falla ‚Üí cambiar a SQL Server en segundos
   - Solo cambiar `DefaultDataSource` y reiniciar

## üéØ Conclusi√≥n

**¬øCumple el prop√≥sito?**
- Arquitectura: ‚úÖ Excelente, preparada para escalar
- Rendimiento actual: ‚ùå Necesita optimizaciones cr√≠ticas
- Rendimiento potencial: ‚úÖ Con optimizaciones ser√° muy r√°pido (< 200ms)

**¬øCambio de origen automatizado?**
- ‚úÖ S√ç, perfectamente automatizado
- ‚úÖ Un solo cambio en configuraci√≥n
- ‚úÖ Cero cambios de c√≥digo
- ‚úÖ Dise√±o futuro-proof para cualquier escenario

**Pr√≥ximo paso recomendado:**
Implementar las optimizaciones de Fase 1 (cr√≠ticas) ANTES de llevar a producci√≥n.

## üêò Optimizaciones Espec√≠ficas para PostgreSQL

### 1. Configuraci√≥n de PostgreSQL Server

**postgresql.conf - Ajustes recomendados para producci√≥n:**

```ini
# MEMORIA
shared_buffers = 4GB                    # 25% de RAM disponible
effective_cache_size = 12GB             # 75% de RAM disponible
work_mem = 50MB                         # Para ordenamientos y hash joins
maintenance_work_mem = 1GB              # Para VACUUM, CREATE INDEX

# PLANIFICADOR DE QUERIES
random_page_cost = 1.1                  # Para SSDs (default es 4.0)
effective_io_concurrency = 200          # Para SSDs (default es 1)
default_statistics_target = 100         # Mejora estad√≠sticas para planner

# ESCRITURA (WAL)
wal_buffers = 16MB
min_wal_size = 1GB
max_wal_size = 4GB
checkpoint_completion_target = 0.9

# PARALELISMO
max_worker_processes = 8
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_parallel_maintenance_workers = 4

# LOGGING (para identificar queries lentas)
log_min_duration_statement = 1000       # Log queries > 1 segundo
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
```

### 2. Monitoreo de Queries Lentas

**Habilitar pg_stat_statements (extensi√≥n de PostgreSQL):**

```sql
-- Ejecutar como superusuario
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Ver queries m√°s lentas
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time,
    rows
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 20;

-- Reset estad√≠sticas
SELECT pg_stat_statements_reset();
```

### 3. VACUUM y ANALYZE Autom√°tico

PostgreSQL acumula "dead tuples" que ralentizan queries. Configurar autovacuum agresivo:

```ini
# postgresql.conf
autovacuum = on
autovacuum_max_workers = 4
autovacuum_naptime = 15s               # Revisar cada 15 segundos
autovacuum_vacuum_threshold = 25       # Menos tuplas muertas para activar
autovacuum_analyze_threshold = 10
```

**Ejecutar VACUUM ANALYZE manualmente despu√©s de cargas masivas:**

```sql
-- Despu√©s de insertar muchos registros
VACUUM ANALYZE "FastServer_LogServices_Header";
```

### 4. Particionamiento de Tablas (Para logs hist√≥ricos)

Si tienes millones de registros, particiona por fecha:

```sql
-- Crear tabla particionada
CREATE TABLE "FastServer_LogServices_Header_Partitioned" (
    LIKE "FastServer_LogServices_Header" INCLUDING ALL
) PARTITION BY RANGE (fastserver_log_date_in);

-- Crear particiones por mes
CREATE TABLE logs_2025_01 PARTITION OF "FastServer_LogServices_Header_Partitioned"
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE logs_2025_02 PARTITION OF "FastServer_LogServices_Header_Partitioned"
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- Crear partici√≥n para futuros meses autom√°ticamente
CREATE OR REPLACE FUNCTION create_partition_if_not_exists()
RETURNS trigger AS $$
BEGIN
    -- L√≥gica para crear particiones autom√°ticamente
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

**Beneficios del particionamiento:**
- Queries solo escanean particiones relevantes
- VACUUM m√°s r√°pido (solo en particiones afectadas)
- F√°cil archivar logs antiguos (DROP partition)
- Queries por fecha 10-100x m√°s r√°pidas

### 5. √çndices BRIN para Datos Temporales

Para logs con muchos registros ordenados por fecha, usar BRIN (Block Range Index):

```sql
-- BRIN es 10-100x m√°s peque√±o que B-tree para datos ordenados
CREATE INDEX ix_logservices_brin_date
ON "FastServer_LogServices_Header"
USING BRIN (fastserver_log_date_in);

-- Combinar con B-tree para otros campos
CREATE INDEX ix_logservices_state_btree
ON "FastServer_LogServices_Header"
USING BTREE (fastserver_log_state);
```

**Cu√°ndo usar BRIN:**
- ‚úÖ Columnas con datos ordenados naturalmente (timestamps, IDs autoincrementales)
- ‚úÖ Tablas grandes (> 1 mill√≥n de registros)
- ‚úÖ Queries con range scans (WHERE date >= X AND date <= Y)
- ‚ùå No usar para datos desordenados

### 6. Configuraci√≥n de Connection Pooling con PgBouncer

Para alta concurrencia, usar PgBouncer como proxy:

```ini
# pgbouncer.ini
[databases]
fastserverlogs = host=localhost port=5432 dbname=FastServerLogs

[pgbouncer]
listen_port = 6432
listen_addr = *
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt
pool_mode = transaction                # M√°s eficiente
max_client_conn = 1000                 # Conexiones de clientes
default_pool_size = 25                 # Conexiones reales a PostgreSQL
reserve_pool_size = 5
reserve_pool_timeout = 3
```

**Cambiar connection string para usar PgBouncer:**
```json
{
  "ConnectionStrings": {
    "PostgreSQL": "Host=localhost;Port=6432;Database=FastServerLogs;..."
  }
}
```

### 7. Explain Analyze para Debugging

**Antes de crear √≠ndices, analiza queries:**

```sql
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT * FROM "FastServer_LogServices_Header"
WHERE fastserver_log_date_in >= '2025-01-01'
ORDER BY fastserver_log_date_in DESC
LIMIT 10;
```

**Qu√© buscar en el output:**
- ‚ùå `Seq Scan` = Escaneo completo de tabla (MALO)
- ‚úÖ `Index Scan` = Usa √≠ndice (BUENO)
- ‚ùå `Buffers: shared hit=1000 read=5000` = Lee mucho desde disco (necesita √≠ndices)
- ‚úÖ `Buffers: shared hit=50 read=0` = Todo en memoria (BUENO)

### 8. Compresi√≥n de Columnas (PostgreSQL 14+)

Para columnas con texto largo (como logs JSON):

```sql
ALTER TABLE "FastServer_LogServices_Header"
ALTER COLUMN fastserver_error_description SET COMPRESSION lz4;

-- O al crear la tabla
CREATE TABLE logs (
    id BIGINT,
    message TEXT COMPRESSION lz4
);
```

### 9. Scripts de Mantenimiento

**Script para ejecutar diariamente:**

```sql
-- 1. Recopilar estad√≠sticas
ANALYZE "FastServer_LogServices_Header";

-- 2. Limpiar tuplas muertas
VACUUM "FastServer_LogServices_Header";

-- 3. Ver bloat (espacio desperdiciado)
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    n_dead_tup
FROM pg_stat_user_tables
WHERE n_dead_tup > 1000
ORDER BY n_dead_tup DESC;

-- 4. Ver √≠ndices no usados (considerar eliminar)
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
    AND indexrelname NOT LIKE '%pkey%'
ORDER BY pg_relation_size(indexrelid) DESC;
```

## üìä M√©tricas Espec√≠ficas PostgreSQL

### Verificar Salud de la Base de Datos:

```sql
-- 1. Cache hit ratio (debe ser > 99%)
SELECT
    sum(heap_blks_read) as heap_read,
    sum(heap_blks_hit) as heap_hit,
    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) * 100 AS cache_hit_ratio
FROM pg_statio_user_tables;

-- 2. Tama√±o de la base de datos
SELECT
    pg_size_pretty(pg_database_size('FastServerLogs')) AS db_size;

-- 3. Tablas m√°s grandes
SELECT
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 10;

-- 4. Queries activas
SELECT
    pid,
    now() - query_start AS duration,
    state,
    query
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY duration DESC;
```

## üéØ Resumen de Optimizaciones PostgreSQL

### Prioridad ALTA (Implementar primero):
1. ‚úÖ Crear √≠ndices b√°sicos (ix_logservices_logdatein, etc.)
2. ‚úÖ Configurar connection pooling en connection string
3. ‚úÖ Habilitar pg_stat_statements para monitoreo
4. ‚úÖ Ajustar shared_buffers y effective_cache_size

### Prioridad MEDIA (Pr√≥ximas semanas):
5. ‚ö†Ô∏è Configurar autovacuum agresivo
6. ‚ö†Ô∏è Implementar BRIN index para timestamps
7. ‚ö†Ô∏è Configurar log_min_duration_statement para queries lentas

### Prioridad BAJA (Cuando haya > 10M registros):
8. üìä Implementar particionamiento por fecha
9. üìä Configurar PgBouncer para alta concurrencia
10. üìä Compresi√≥n de columnas de texto largo
